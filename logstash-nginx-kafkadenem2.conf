input {
    kafka {
      bootstrap_servers => "{KAFKASERVERIP}:9092"
      topics => "filebeat"
    }
}

filter {
  if [input][type] == "log" {
      if [message] =~ "^#" {
        drop {}
      }
      grok {
         match => { "message" => "\[%{HTTPDATE:logtimestamp}\] %{IPORHOST:clientip} %{IPORHOST:sitename} request_time: %{NUMBER:request_time} Referer: %{URI:referrer} Uri: %{URIPATH:uri} HttpStatus: %{NUMBER:http_status}"
         }
      }
      mutate {
        convert => { "http_status" => "integer" }
        convert => { "request_time" => "integer" }
      }
  }

  if [input][type] == "container" {
    grok {
      patterns_dir => "/etc/logstash/pattern"
      match => { "message" => "%{IPORHOST:clientip} %{NGUSER:ident} %{NGUSER:auth} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{URIPATHPARAM:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response}" }
    }
  }

  if [fileset][name] == "syslog" {
      grok {
        match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
        add_field => [ "received_at", "%{@timestamp}" ]
        add_field => [ "received_from", "%{host}" ]
      }
      syslog_pri { }
      date {
        match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
      }
      mutate {
        add_tag => ["syslog"]
      }
   }
}
output {
  if "syslog" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "syslog-%{+YYYY.MM.dd}"
      user => "elastic"
      password => "{password}"
    }
  }

  if "docker" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "docker-%{+YYYY.MM.dd}"
      user => "elastic"
      password => "{password}"
    }

  }

  if "nginx" in [tags] {
    elasticsearch {
      hosts => ["localhost:9200"]
      index => "nginxlogs-%{+YYYY.MM.dd}"
      user => "elastic"
      password => "{password}"
   }
 }
}
